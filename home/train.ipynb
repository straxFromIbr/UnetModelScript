{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9899e3-c06b-4ec4-a6e9-e5ba034efe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import unet, losses, metrics\n",
    "\n",
    "import config\n",
    "from utils import callbacks\n",
    "from dataset import mk_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets():\n",
    "    train_ds = mk_dataset.mk_dataset(\n",
    "        SAT_PATH=config.TR_SAT_PATH,\n",
    "        MAP_PATH=config.TR_MAP_PATH,\n",
    "    )\n",
    "    valid_ds = mk_dataset.mk_dataset(\n",
    "        SAT_PATH=config.VA_SAT_PATH,\n",
    "        MAP_PATH=config.VA_MAP_PATH,\n",
    "        batch_size=1,\n",
    "    )\n",
    "    return train_ds, valid_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c663fd2-1174-4fe9-a6c5-3439af5d130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "def compile_model(loss, optimizer):\n",
    "    input_shape = (config.IMG_HEIGHT, config.IMG_WIDTH, config.IMG_CH)\n",
    "    model = unet.big_unet_model(\n",
    "        input_shape=input_shape,\n",
    "        output_channels=config.OUT_CH,\n",
    "    )\n",
    "    # Compile the model\n",
    "    metric_list = [\"accuracy\", metrics.iou_coef]\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metric_list)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Model shape\n",
    "\n",
    "def get_callbacks(filename):\n",
    "    tboard_cb = callbacks.get_tboard_callback(str(config.LOG_PATH / filename))\n",
    "    checkpoint_cb = callbacks.get_checkpoint_callback(\n",
    "        str(config.CHECKPOINT_PATH / filename)\n",
    "    )\n",
    "    callback_list = [tboard_cb, checkpoint_cb]\n",
    "    return callback_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b13a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_ds, valid_ds, NB_EPOCHS, loss, optimizer=keras.optimizers.Adam()):\n",
    "    NB_Epochs = 10\n",
    "    model = compile_model(loss=loss, optimizer=optimizer)\n",
    "    filename = datetime.now().strftime(\"%Y%m%d%H%M_\") + model.loss.name\n",
    "    model_history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=NB_Epochs,\n",
    "        steps_per_epoch=config.STEPS_PER_EPOCH,\n",
    "        validation_steps=config.VALIDATION_STEPS,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=get_callbacks(filename),\n",
    "    )\n",
    "    model.save(str(config.MODEL_SAVE_PATH / filename))\n",
    "    return model_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    lossfunc_list = [\n",
    "        losses.DICELoss(name=\"DICE\"),\n",
    "        losses.FocalTverskyLoss(\"Focal\"),\n",
    "        losses.TverskyLoss(\"Tversky\"),\n",
    "    ]\n",
    "    train_ds, valid_ds = make_datasets()\n",
    "    for loss in lossfunc_list:\n",
    "        hist = train(\n",
    "            train_ds=train_ds,\n",
    "            valid_ds=valid_ds,\n",
    "            NB_EPOCHS=10,\n",
    "            loss=loss,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4777fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0dbd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in valid_ds.take(2):\n",
    "    t_pred = model.predict(i)\n",
    "    plt.imshow(i[0])\n",
    "    plt.show()\n",
    "    plt.imshow(t[0])\n",
    "    plt.show()\n",
    "    plt.imshow(t_pred[0][:, :, 0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_history.history[\"loss\"]\n",
    "# val_loss = model_history.history[\"val_loss\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(model_history.epoch, loss, \"r\", label=\"Training loss\")\n",
    "plt.plot(model_history.epoch, val_loss, \"bo\", label=\"Validation loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.savefig(\"10282205.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(sample_inp)\n",
    "pred.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f30c1aedcc158e6e85aa10894a7cc9894d5dc80bbbec0a0c9208a77c21f685c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
