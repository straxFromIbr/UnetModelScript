{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from skimage import io as skio\n",
    "from skimage import transform\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pathlib\n",
    "from dataset_utils import mk_dataset\n",
    "from model import residual_unet, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pret=None, freeze_enc=False, freeze_dec=False):\n",
    "    input_shape = (256, 256, 3)\n",
    "    model = residual_unet.unet(\n",
    "        input_shape,\n",
    "        name=\"unet\",\n",
    "        parallel_dilated=True,\n",
    "    )\n",
    "    if pret is not None:\n",
    "        model.load_weights(pret)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if \"down\" in layer.name and freeze_enc:\n",
    "            layer.trainable = False\n",
    "        if \"up\" in layer.name and freeze_dec:\n",
    "            layer.trainable = False\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001, name=\"adam\")\n",
    "    loss = losses.DICELoss(name=\"dice\")\n",
    "    metrics = (\n",
    "        keras.metrics.MeanIoU(num_classes=2, name=\"mean_iou\"),\n",
    "        keras.metrics.Precision(name=\"presision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "    )\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "pret = \"/Volumes/GoogleDrive/マイドライブ/卒研/220111/checkpoints/DA_FRZ-DICE-E50-MR1.0/DA_FRZ-DICE-E50-MR1.0\"\n",
    "model = build_model(pret)\n",
    "model.save_weights(\"DA_FRZ-DICE-E50-MR1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "input_shape = (256, 256, 3)\n",
    "model = residual_unet.unet(\n",
    "    input_shape,\n",
    "    name=\"unet\",\n",
    "    parallel_dilated=True,\n",
    ")\n",
    "model.load_weights(\"DA_FRZ-DICE-E50-MR1.0\")\n",
    "model.save(\"DA_FRZ-DICE-E50-MR1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = keras.models.load_model(\"DA_FRZ-DICE-E50-MR1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"basemodel_DA_FZHB-DICE-MR-E50\")\n",
    "\n",
    "freeze_enc = True\n",
    "freeze_dec = False\n",
    "for layer in model.layers:\n",
    "    if \"down\" in layer.name and freeze_enc:\n",
    "        layer.trainable = False\n",
    "    if \"up\" in layer.name and freeze_dec:\n",
    "        layer.trainable = False\n",
    "[(layer.name, layer.trainable) for layer in model.layers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gends(ds_root, suffix):\n",
    "    ds_root = pathlib.Path(ds_root)\n",
    "    pathlist = ds_root.glob(f\"map/*.{suffix}\")\n",
    "    pathlist = sorted([path.name for path in pathlist])\n",
    "    sat_pathlist = sorted([str(ds_root / \"sat\" / path) for path in pathlist])\n",
    "    map_pathlist = sorted([str(ds_root / \"map\" / path) for path in pathlist])\n",
    "    test_ds = mk_dataset.mkds(sat_pathlist, map_pathlist, batch_size=32, test=True)\n",
    "    return test_ds.shuffle(1000)\n",
    "\n",
    "\n",
    "def show_results(images, titles, figsize=(30, 30)):\n",
    "    nb_images = len(images)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for idx, (image, title) in enumerate(zip(images, titles)):\n",
    "        if len(image.shape) and image.shape[-1] == 1:\n",
    "            image = image[..., 0]\n",
    "        plt.subplot(1, nb_images, idx + 1)\n",
    "        plt.title(title)\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"../../../Datasets/mass_roads9/valid\")\n",
    "path.exists()\n",
    "ds = gends(path, \"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, tar = next(iter(ds))\n",
    "pred = model.predict(im)\n",
    "idx = random.randrange(32)\n",
    "print(idx)\n",
    "show_results((pred[idx], im[idx], tar[idx]), (\"_\", \"_\", \"_\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DICELoss(keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Tversky損失の`alpha`=0.5であるが継承せずため独立に実装\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=None):\n",
    "        \"\"\"\n",
    "        ゼロ除算対策のためのパラメータ設定\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        self.smooth = 1e-10\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_pos = tf.reshape(y_true, [-1])\n",
    "        y_pred_pos = tf.reshape(y_pred, [-1])\n",
    "        tp_mul = tf.math.reduce_sum(y_true_pos * y_pred_pos)\n",
    "        tp_sum = tf.math.reduce_sum(y_true_pos + y_pred_pos)\n",
    "        dc = 2 * (tp_mul + self.smooth) / (tp_sum + self.smooth)\n",
    "        return 1.0 - dc\n",
    "\n",
    "dice = DICELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/hagayuya/Datasets/mass_roads9/valid/sat/10978735_15_3_1_2.png\"\n",
    "org_im = skio.imread(path)\n",
    "path = \"/Users/hagayuya/Datasets/mass_roads9/valid/map/10978735_15_3_1_2.png\"\n",
    "org_ta = skio.imread(path, as_gray=True)[..., None]\n",
    "\n",
    "h = org_im.shape[0]\n",
    "for size in range(1, 11 ):\n",
    "    crop_size = int(h * 0.1 * size)\n",
    "\n",
    "    im = org_im[:crop_size, :crop_size]\n",
    "    im = transform.resize(im, (256, 256))\n",
    "    tar = org_ta[:crop_size, :crop_size]\n",
    "    tar = transform.resize(tar, (256, 256))\n",
    "    pred = model.predict(im[None])[0]\n",
    "    pred = tf.convert_to_tensor(pred, dtype=\"float64\")\n",
    "    tar = tf.convert_to_tensor(tar, dtype=\"float64\")\n",
    "    print(dice(pred[None], tar[None]).numpy())\n",
    "    show_results((pred, im + pred, tar), (\"_\", \"_\", \"_\"), (10, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10c0896c0a6005b65426c8744684cff745857a6f8f225d876aca5995a0e5eac1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf3.9': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
